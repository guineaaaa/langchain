from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, OpenAI
from langchain_community.document_loaders import TextLoader  # âœ… ì—¬ê¸° ìˆ˜ì •ë¨
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from dotenv import load_dotenv
import os

# ğŸŒ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤!")

# ë¬¸ì„œ ë¡œë”©
loader = TextLoader("news.txt", encoding="utf-8")
documents = loader.load()

# ë¬¸ì„œ ë¶„í• 
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = splitter.split_documents(documents)

# ì„ë² ë”© ë° ë²¡í„° DB ìƒì„±
embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)
vectordb = FAISS.from_documents(docs, embedding)

# RAG ì²´ì¸ êµ¬ì„±
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(openai_api_key=openai_api_key),
    retriever=vectordb.as_retriever()
)

# ì§ˆë¬¸ ë£¨í”„
while True:
    query=input("ë‰´ìŠ¤ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš” (exit ì…ë ¥ ì‹œ ì¢…ë£Œ): ")
    if query.lower()=="exit":
        break
    answer=qa.invoke({"query":query})
    print(f"\n ë‹µë³€: {answer}\n")